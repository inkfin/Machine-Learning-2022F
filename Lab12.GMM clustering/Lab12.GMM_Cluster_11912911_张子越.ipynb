{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB12.GMM Cluster Assignment\n",
    "> 11912911 张子越\n",
    "\n",
    "Please finish the **Exercise** and answer **Questions**.\n",
    "### Exercise (100 Points)\n",
    "In this lab, our goal is to write a program to segment different objects using the **GMM and EM** algorithm. We also use <u>*k-means* clustering algorithm to initialize the parameters</u> of GMM. The following steps should be implemented to achieve such a goal:\n",
    "\n",
    "1. Load image\n",
    "2. Initialize parameters of GMM using K-means\n",
    "3. Implement the EM algorithm for GMM\n",
    "4. Display result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.cluster import KMeans\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "COLORS = [\n",
    "    (255, 0, 0),   # red\n",
    "    (0, 255, 0),  # green\n",
    "    (0, 0, 255),   # blue\n",
    "    (255, 255, 0), # yellow\n",
    "    (255, 0, 255), # magenta\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Image\n",
    "What you should do is to implement Z-score normalization in `load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w, c = image.shape  # height, width, channel\n",
    "\n",
    "    # please normalize image_pixl using Z-score\n",
    "    _mean = np.mean(image)\n",
    "    _std = np.sqrt(np.mean(np.square(image - _mean)))\n",
    "    image_norm = (image - _mean) / _std\n",
    "\n",
    "    return h, w, c, image_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 402, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = './images/image-20220804223008133.png'\n",
    "\n",
    "h, w, c, image_norm = load(image_path)\n",
    "h, w, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize means, covariance matrices and mixing coefficients of GMM\n",
    "k-means is used to initialize means, covariance matrices and mixing coefficients of GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(n_cluster, image_pixl):\n",
    "    kmeans = KMeans(n_clusters=n_cluster)# instantiate a K-means\n",
    "    labels = kmeans.fit_predict(image_pixl)# fit and get clustering result\n",
    "    initial_mus = kmeans.cluster_centers_# get centroids\n",
    "    initial_priors, initial_covs = [], []\n",
    "    #Followings are for initialization:\n",
    "    for i in range(n_cluster):\n",
    "        datas = image_pixl[labels == i, ...].T\n",
    "        initial_covs.append(np.cov(datas))\n",
    "        initial_priors.append(datas.shape[1] / len(labels))\n",
    "    return initial_mus, initial_priors, initial_covs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement GMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, ncomp, initial_mus, initial_covs, initial_priors):\n",
    "        \"\"\"\n",
    "        :param ncomp:           the number of clusters\n",
    "        :param initial_mus:     initial means\n",
    "        :param initial_covs:    initial covariance matrices\n",
    "        :param initial_priors:  initial mixing coefficients\n",
    "        \"\"\"\n",
    "        self.ncomp = ncomp\n",
    "        self.mus = np.asarray(initial_mus)\n",
    "        self.covs = np.asarray(initial_covs)\n",
    "        self.priors = np.asarray(initial_priors)\n",
    "\n",
    "    def inference(self, datas):\n",
    "        \"\"\"\n",
    "        E-step\n",
    "        :param datas:   original data\n",
    "        :return:        posterior probability (gamma) and log likelihood\n",
    "        \"\"\"\n",
    "        probs = []\n",
    "        for i in range(self.ncomp):\n",
    "            mu, cov, prior = self.mus[i, :], self.covs[i, :, :], self.priors[i]\n",
    "            prob = prior * multivariate_normal.pdf(datas, mean=mu, cov=cov, allow_singular=True)\n",
    "            probs.append(np.expand_dims(prob, -1))\n",
    "        preds = np.concatenate(probs, axis=1)\n",
    "\n",
    "        # TODO: calc log likelihood\n",
    "        plog = np.log(np.sum(preds, axis=1))\n",
    "        log_likelihood = np.sum(plog)\n",
    "\n",
    "        # TODO: calc gamma\n",
    "        numerator = preds\n",
    "        denominator = np.sum(preds, axis=1, keepdims=True)\n",
    "        gamma = np.asarray(numerator / denominator)\n",
    "\n",
    "        return gamma, log_likelihood\n",
    "\n",
    "    def update(self, datas, gamma):\n",
    "        \"\"\"\n",
    "        M-step\n",
    "        :param datas:   original data\n",
    "        :param gamma:   gamma\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_mus, new_covs, new_priors = [], [], []\n",
    "        soft_counts = np.sum(gamma, axis=0)\n",
    "        for i in range(self.ncomp):\n",
    "            # TODO: calc mu\n",
    "            new_mu = np.sum(np.expand_dims(gamma[:,i], -1) * datas, axis=0) / soft_counts[i]\n",
    "            new_mus.append(new_mu)\n",
    "\n",
    "            # TODO: calc cov\n",
    "            data_ = datas - np.expand_dims(new_mu, 0)\n",
    "            new_cov = (np.expand_dims(gamma[:,i], -1) * data_).T * data_ / soft_counts[i]\n",
    "            new_covs.append(new_cov)\n",
    "\n",
    "            # TODO: calc mixing coefficients\n",
    "            new_prior = soft_counts[i] / np.sum(soft_counts)\n",
    "            new_priors.append(new_prior)\n",
    "\n",
    "        self.mus = np.asarray(new_mus)\n",
    "        self.covs = np.asarray(new_covs)\n",
    "        self.priors = np.asarray(new_priors)\n",
    "\n",
    "    def fit(self, data, iteration):\n",
    "        prev_log_liklihood = None\n",
    "\n",
    "        bar = tqdm.tqdm(total=iteration)\n",
    "        for i in range(iteration):\n",
    "            gamma, log_likelihood = self.inference(data)\n",
    "            self.update(data, gamma)\n",
    "            if prev_log_liklihood is not None and abs(log_likelihood - prev_log_liklihood) < 1e-10:\n",
    "                break\n",
    "            prev_log_likelihood = log_likelihood\n",
    "\n",
    "            bar.update()\n",
    "            bar.set_postfix({\"log likelihood\": log_likelihood})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display\n",
    "We use `matplotlib` to display what we segment, you can check the code in `visualize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize(gmm, image, ncomp, ih, iw):\n",
    "    beliefs, log_likelihood = gmm.inference(image)\n",
    "    map_beliefs = np.reshape(beliefs, (ih, iw, ncomp))\n",
    "    segmented_map = np.zeros((ih, iw, 3))\n",
    "    for i in range(ih):\n",
    "        for j in range(iw):\n",
    "            hard_belief = np.argmax(map_beliefs[i, j, :])\n",
    "            segmented_map[i, j, :] = np.asarray(COLORS[hard_belief]) / 255.0\n",
    "    plt.imshow(segmented_map)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. KMeans expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m iteration\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# init mu, prior and cov\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m initial_mus, initial_priors, initial_covs \u001b[39m=\u001b[39m kmeans(ncomp, image_norm)\n\u001b[1;32m      7\u001b[0m \u001b[39m# GMM\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGMM begins...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m, in \u001b[0;36mkmeans\u001b[0;34m(n_cluster, image_pixl)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkmeans\u001b[39m(n_cluster, image_pixl):\n\u001b[1;32m      2\u001b[0m     kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39mn_cluster)\u001b[39m# instantiate a K-means\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     labels \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39;49mfit_predict(image_pixl)\u001b[39m# fit and get clustering result\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     initial_mus \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mcluster_centers_\u001b[39m# get centroids\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     initial_priors, initial_covs \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/yolov5/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:996\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    974\u001b[0m     \u001b[39m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \n\u001b[1;32m    976\u001b[0m \u001b[39m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[39m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, sample_weight\u001b[39m=\u001b[39;49msample_weight)\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/yolov5/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1367\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1342\u001b[0m     \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \n\u001b[1;32m   1344\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1367\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1368\u001b[0m         X,\n\u001b[1;32m   1369\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1370\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   1371\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1372\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[1;32m   1373\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1374\u001b[0m     )\n\u001b[1;32m   1376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X)\n\u001b[1;32m   1377\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/yolov5/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/yolov5/lib/python3.8/site-packages/sklearn/utils/validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    899\u001b[0m     _assert_all_finite(\n\u001b[1;32m    900\u001b[0m         array,\n\u001b[1;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. KMeans expected <= 2."
     ]
    }
   ],
   "source": [
    "ih, iw, ic, image_norm = load(\"data/original/sample.png\")\n",
    "ncomp = 3\n",
    "iteration=500\n",
    "# init mu, prior and cov\n",
    "initial_mus, initial_priors, initial_covs = kmeans(ncomp, image_norm)\n",
    "\n",
    "# GMM\n",
    "print(\"GMM begins...\")\n",
    "gmm = GMM(ncomp, initial_mus, initial_covs, initial_priors)\n",
    "gmm.fit(image_norm, iteration)\n",
    "\n",
    "# visualize\n",
    "visualize(gmm, image_norm, ncomp, ih, iw)\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample Result\n",
    "<img src=\"images/image-20220804223008133.png\" alt=\"image-20220804223008133\" style=\"zoom:67%;\" />\n",
    "<img src=\"images/image-20220804222915979.png\" alt=\"image-20220804222915979\" style=\"zoom: 67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions(3 points)\n",
    "1. What are the strengths of GMM; when does it perform well?\n",
    "2. What are the weaknesses of GMM; when does it perform poorly?\n",
    "3. What makes GMM a good candidate for the clustering problem, if you have enough knowledge about the data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f958ded69c140b726e5738806c4a1486669a4cc19ba396882dbf1aafa176391f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
