{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB12.GMM Cluster Assignment\n",
    "> 11912911 张子越\n",
    "\n",
    "Please finish the **Exercise** and answer **Questions**.\n",
    "### Exercise (100 Points)\n",
    "In this lab, our goal is to write a program to segment different objects using the **GMM and EM** algorithm. We also use <u>*k-means* clustering algorithm to initialize the parameters</u> of GMM. The following steps should be implemented to achieve such a goal:\n",
    "\n",
    "1. Load image\n",
    "2. Initialize parameters of GMM using K-means\n",
    "3. Implement the EM algorithm for GMM\n",
    "4. Display result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.cluster import KMeans\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "COLORS = [\n",
    "    (255, 0, 0),   # red\n",
    "    (0, 255, 0),  # green\n",
    "    (0, 0, 255),   # blue\n",
    "    (255, 255, 0), # yellow\n",
    "    (255, 0, 255), # magenta\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Image\n",
    "What you should do is to implement Z-score normalization in `load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w, c = image.shape  # height, width, channel\n",
    "\n",
    "    # please normalize image_pixl using Z-score\n",
    "    _mean = np.mean(image)\n",
    "    _std = np.sqrt(np.mean(np.square(image - _mean)))\n",
    "    image_norm = (image - _mean) / _std\n",
    "\n",
    "    return h, w, c, image_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 402, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = './images/image-20220804223008133.png'\n",
    "\n",
    "h, w, c, image_norm = load(image_path)\n",
    "h, w, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize means, covariance matrices and mixing coefficients of GMM\n",
    "k-means is used to initialize means, covariance matrices and mixing coefficients of GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(n_cluster, image_pixl):\n",
    "    kmeans = KMeans(n_clusters=n_cluster)# instantiate a K-means\n",
    "    labels = kmeans.fit_predict(image_pixl)# fit and get clustering result\n",
    "    initial_mus = kmeans.cluster_centers_# get centroids\n",
    "    initial_priors, initial_covs = [], []\n",
    "    #Followings are for initialization:\n",
    "    for i in range(n_cluster):\n",
    "        datas = image_pixl[labels == i, ...].T\n",
    "        initial_covs.append(np.cov(datas))\n",
    "        initial_priors.append(datas.shape[1] / len(labels))\n",
    "    return initial_mus, initial_priors, initial_covs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement GMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, ncomp, initial_mus, initial_covs, initial_priors):\n",
    "        \"\"\"\n",
    "        :param ncomp:           the number of clusters\n",
    "        :param initial_mus:     initial means\n",
    "        :param initial_covs:    initial covariance matrices\n",
    "        :param initial_priors:  initial mixing coefficients\n",
    "        \"\"\"\n",
    "        self.ncomp = ncomp\n",
    "        self.mus = np.asarray(initial_mus)\n",
    "        self.covs = np.asarray(initial_covs)\n",
    "        self.priors = np.asarray(initial_priors)\n",
    "\n",
    "    def inference(self, datas):\n",
    "        \"\"\"\n",
    "        E-step\n",
    "        :param datas:   original data\n",
    "        :return:        posterior probability (gamma) and log likelihood\n",
    "        \"\"\"\n",
    "        probs = []\n",
    "        for i in range(self.ncomp):\n",
    "            mu, cov, prior = self.mus[i, :], self.covs[i, :, :], self.priors[i]\n",
    "            prob = prior * multivariate_normal.pdf(datas, mean=mu, cov=cov, allow_singular=True)\n",
    "            probs.append(np.expand_dims(prob, -1))\n",
    "        preds = np.concatenate(probs, axis=1)\n",
    "\n",
    "        # TODO: calc log likelihood\n",
    "        log_likelihood = None\n",
    "\n",
    "        # TODO: calc gamma\n",
    "        gamma = None\n",
    "\n",
    "        return gamma, log_likelihood\n",
    "\n",
    "    def update(self, datas, gamma):\n",
    "        \"\"\"\n",
    "        M-step\n",
    "        :param datas:   original data\n",
    "        :param gamma:   gamma\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_mus, new_covs, new_priors = [], [], []\n",
    "        soft_counts = np.sum(gamma, axis=0)\n",
    "        for i in range(self.ncomp):\n",
    "            # TODO: calc mu\n",
    "            new_mu = None\n",
    "            new_mus.append(new_mu)\n",
    "\n",
    "            # TODO: calc cov\n",
    "            new_cov = None\n",
    "            new_covs.append(new_cov)\n",
    "\n",
    "            # TODO: calc mixing coefficients\n",
    "            new_prior = None\n",
    "            new_priors.append(new_prior)\n",
    "\n",
    "        self.mus = np.asarray(new_mus)\n",
    "        self.covs = np.asarray(new_covs)\n",
    "        self.priors = np.asarray(new_priors)\n",
    "\n",
    "    def fit(self, data, iteration):\n",
    "        prev_log_liklihood = None\n",
    "\n",
    "        bar = tqdm.tqdm(total=iteration)\n",
    "        for i in range(iteration):\n",
    "            gamma, log_likelihood = self.inference(data)\n",
    "            self.update(data, gamma)\n",
    "            if prev_log_liklihood is not None and abs(log_likelihood - prev_log_liklihood) < 1e-10:\n",
    "                break\n",
    "            prev_log_likelihood = log_likelihood\n",
    "\n",
    "            bar.update()\n",
    "            bar.set_postfix({\"log likelihood\": log_likelihood})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display\n",
    "We use `matplotlib` to display what we segment, you can check the code in `visualize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize(gmm, image, ncomp, ih, iw):\n",
    "    beliefs, log_likelihood = gmm.inference(image)\n",
    "    map_beliefs = np.reshape(beliefs, (ih, iw, ncomp))\n",
    "    segmented_map = np.zeros((ih, iw, 3))\n",
    "    for i in range(ih):\n",
    "        for j in range(iw):\n",
    "            hard_belief = np.argmax(map_beliefs[i, j, :])\n",
    "            segmented_map[i, j, :] = np.asarray(COLORS[hard_belief]) / 255.0\n",
    "    plt.imshow(segmented_map)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample Result\n",
    "<img src=\"images/image-20220804223008133.png\" alt=\"image-20220804223008133\" style=\"zoom:67%;\" />\n",
    "<img src=\"images/image-20220804222915979.png\" alt=\"image-20220804222915979\" style=\"zoom: 67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions(3 points)\n",
    "1. What are the strengths of GMM; when does it perform well?\n",
    "2. What are the weaknesses of GMM; when does it perform poorly?\n",
    "3. What makes GMM a good candidate for the clustering problem, if you have enough knowledge about the data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f958ded69c140b726e5738806c4a1486669a4cc19ba396882dbf1aafa176391f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
